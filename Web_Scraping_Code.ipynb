{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workforce Acquisition Using Text Mining - Web Scraping\n",
    "\n",
    "Group 8 - \n",
    "\n",
    "Dhananjay Singh - 668437546\n",
    "Shivani Narahari - 663244158\n",
    "Srinanda Kurapati - 675954089\n",
    "\n",
    "Our primary goal was to acquire all the job descriptions from Amazon/jobs for a certain setting of filters. Simple web scraping was incovenient, hence we automated the process using Selenium Webdriver. \n",
    "Following is the code for scraping job descriptions for every job present in 24 pages automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading selenium library\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.path.dirname(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing webdriver and time libaries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Qualifications XPath        /html/body/div[2]/div[1]/div[4]/div[2]/div/div[1]/div/div[3]/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selenium works on accessing web elements. Web elements could be buttons, links, text and they can be referenced using ID's, names, classes etc. One reliable way of accessing web elements is to use XPaths. \n",
    "#Amazon jobs site had all its jobs and details listed in a structured manner that remained consistent across every page. Therefore using the Xpath approach was useful for us. \n",
    "#The following is the list of Xpaths that were used for accessing job titles and their descriptions\n",
    "ListOfXpaths=[\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[1]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[2]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[3]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[4]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[5]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[6]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[7]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[8]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[9]/a/div/div[1]/div[1]/h3\",\n",
    "\n",
    "\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[2]/div/div[10]/a/div/div[1]/div[1]/h3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobIDXpath =\"/html/body/div[2]/div[1]/div[4]/div[1]/div/div/div/div[1]/div/div/p\"\n",
    "basicXpath=\"/html/body/div[2]/div[1]/div[4]/div[2]/div/div[1]/div/div[3]/p\"\n",
    "preferredXpath=\"/html/body/div[2]/div[1]/div[4]/div[2]/div/div[1]/div/div[4]/p\"\n",
    "nextButtonXpath=\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[3]/div[1]/div/div/button[7]\"\n",
    "lastPageXpath=\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[3]/div[1]/div/div/button[8]\"\n",
    "nextTraverse=\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[3]/div[1]/div/div/button[\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ListOfXpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary. This will hold all our scraped data\n",
    "job_des={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Chrome Driver Manager\n",
    "!pip install webdriver-manager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every web element on a page, every functionality can be accessed only through the driver. \n",
    "#Here we give the URL to be accessed, give directions to the driver to access required elements of the web pages and then acquire the text from the target locations\n",
    "driver = webdriver.Chrome(\"/Users/shivaninarahari/Downloads/chromedriver\")\n",
    "driver.get('https://www.amazon.jobs/en/business_categories/student-programs?offset=0&result_limit=10&sort=relevant&job_type%5B%5D=Full-Time&cities%5B%5D=Seattle%2C%20Washington%2C%20USA&cities%5B%5D=Singapore%2C%20SGP&cities%5B%5D=Bengaluru%2C%20Karnataka%2C%20IND&cities%5B%5D=Munich%2C%20Bavaria%2C%20DEU&cities%5B%5D=Madrid%2C%20Community%20of%20Madrid%2C%20ESP&cities%5B%5D=London%2C%20England%2C%20GBR&cities%5B%5D=Berlin%2C%20Berlin%2C%20DEU&cities%5B%5D=Luxembourg%2C%20Luxembourg%2C%20LUX&cities%5B%5D=Amsterdam%2C%20North%20Holland%2C%20NLD&cities%5B%5D=Riyadh%2C%20SAU&cities%5B%5D=Milan%2C%20Lombardy%2C%20ITA&distanceType=Mi&radius=24km&latitude=&longitude=&loc_group_id=&loc_query=&base_query=&city=&country=&region=&county=&query_options=&')\n",
    "lastPage=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[6]/div[2]/div/div/div[2]/content/div/div/div[2]/div[3]/div[1]/div/div/button[6]\").text\n",
    "print(\"last\",lastPage)\n",
    "lastPage=int(lastPage)\n",
    "page=0\n",
    "#for page in range(2,lastPage+1):\n",
    "while True:\n",
    "    print(\"page value\",page)\n",
    "    for xpathItem in ListOfXpaths:\n",
    "            print(\"path\",xpathItem)\n",
    "            time.sleep(1)\n",
    "            driver.find_element(by=By.XPATH,value=xpathItem).click()\n",
    "            jobID=driver.find_element(by=By.XPATH,value=jobIDXpath).text\n",
    "            basic= driver.find_element(by=By.XPATH,value=basicXpath).text \n",
    "            preferred=driver.find_element(by=By.XPATH,value=preferredXpath).text\n",
    "            job_des[jobID]=basic+\".\"+preferred\n",
    "            \n",
    "            driver.back()\n",
    "    print(\"the page is \",page)\n",
    "    xpathFinal=nextTraverse+str(page)+\"]\"\n",
    "    print(\"xpath is\",xpathFinal)\n",
    "    #driver.find_element(by=By.XPATH,value=xpathFinal).click()\n",
    "    #driver.find_element_by_link_text(\"Next->\").click()\n",
    "    nxt= driver.find_element_by_class_name('right')\n",
    "    nxt.click()\n",
    "    \n",
    "           \n",
    "    \n",
    "print(job_des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The job_des dictionary has job id's as the key and the job descriptions as their corresponding values\n",
    "#We convert this into a dataframe to be able to conveniently edit it or download it into a CSV file\n",
    "joblist=list(job_des.items())\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "job_df=pd.DataFrame(joblist)\n",
    "\n",
    "print(job_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dataframe to CSV \n",
    "import csv\n",
    "job_df.to_csv ('AmazonJobs.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using one of the keys to find the respective value/job description\n",
    "job_des['Job ID: 1958531 | Afaq Q Tech General Trading']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
